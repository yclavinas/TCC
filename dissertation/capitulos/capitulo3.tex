%TODO: get some info from descricaoDetalhada
\chapter{Models}~\label{chapter3}
As stated in the Section \ref{testing}, all forecast models proposed for this study are based in the Collaboratory for the Study of Earthquake Predictability (CSEP) framework.\\

We propose four forecast model methods. The main difference between them is that they have different genome representation. The genome for each forecast model focus on different aspects of the framework, therefore their represantion vary.\\

The first method is the GAModel~\cite{ecta14}, a statistical method of analysis of
earthquakes risk using the Genetic Algorithm technique (GA). It is a straight application of the CSEP framework. The next method is a specialization of GAModel. It focuses only on areas on which earthquakes happened already in a near past. This will lead to a faster convergence, once the amount of parameters is smaller and consequently, the search space gets smaller. We called it ReducedGAModel(bad name? suggestions?). These methods useonly computational algorithms and techniques.\\

Another method is the Emp-GAModel (bad name? suggestions?). This method incorpores some
geophysical knowledge. It is a hybridization of the models generated by the GAModel with some empirical laws that will be discussed further, in Section \ref{m+a+e}. We also applied these empirical laws in the ReducedGAModel, and name it Emp-ReducedGAModel.\\

%TODO: realocate to->???
For all methods, the population is evolved taking into account earthquake event data for a training period, which is anterior to the target test period. After completing the evaluation stop criteria, the best individual is chosen to be the representative forecast model for that method.\\

\section{1-year Forecast Models}\label{1year-model}
Based on the gridded rate forecast explained in the last Chapter~\ref{chapter2}, we developed earthquake forecasts methods that will estimate the risk of earthquakes occurrence to a target region, during a time interval. Some of the methods also may estime the magnitude of these shocks. For this study we considered the target time interval of one year~\cite{ecta14}.\\

There is no physical measurement to identify mainshocks and its aftershocks~\cite{schorlemmer2010first}, we divided the forecast models in two classes: the ones that only forecasts mainshocks, using only GA techniques, and those that forecast both mainshocks and aftershocks using both GA techniques and empirical laws, such as the modified Omori law. These laws are use to derive the aftershocks from a sintetic data of mainshocks.\\

%TODO: explain better what mainshock and aftershock are
Mainshocks are large and independent earthquakes. They are followed by a wave of others earthquakes, the aftershocks~\cite{schorlemmer2010first}.\\

\section{Mainshock Models}
\subsection{GAModel}\label{GAModel}
The GAModel is completely based on the framework suggested by the CSEP. In it, one forecast is defined as a region in a specfic time interval and is divided in bins. Each bin represents a geographical interval. The whole target area of study is covered by a group of these bins where each bin has an earthquake forecast value. This groups of bin represent the $\mu(x,y)$, the background intensity~\cite{zhuang2004analyzing}. In the GAModel, each possible solution is represented as an entire forecast model.\\

In this context the GAModel is considered as one method to generate
space-rate-time forecasts. It also could be described as:
\begin{equation}\label{gamodel}
 \Lambda(t,x,y,M|\Upsilon_t) = \mu(x,y)
\end{equation}
where you can denote the number of earthquakes forecast in all bins 
as $\Lambda(t,x,y)$~\cite{zechar2010evaluating} given that $\Upsilon_t$ 
is the earthquake observation data up to time $t$.\\

The GAModel forecasts only earthquakes with magnitude greater than 3.0, for every scenario proposed. The space interval for the magnitude is 0.1, named as cells. That results in magnitude cells of [3.0, 3.1), [3.1, 3.2), until [9.9, 10).\\

\subsection{Genome Representation}
In the GAModel each individual represents an entire forecast model. Each gene of the individual is a real value, corresponding to one bin in the desired model. The values are sampled from the interval [0, 1). These real values are converted to a integer forecast, we use the same modification of the Poisson deviates extraction algorithm~\ref{inversePoisson} used in~\cite{ecta14}. In the algorithm $x$ is the real value that will be converted and $\mu$ is the mean of the earthquakes observations in the real data. \\

\begin{algorithm}\label{inversePoisson}
  \caption{Obtain a Poisson deviate from a $[0,1)$ value}
  \label{InversePoisson}
  \begin{algorithmic}
    \STATE Parameters $0 \leq x < 1, \mu \geq 0$
    \STATE $L \gets \exp{(-\mu)}, k \gets 0, prob \gets 1$
    \REPEAT 
    \STATE $\text{increment }k$
    \STATE $prob \gets prob*x$
    \UNTIL{$prob > L$}
    \RETURN $k$
  \end{algorithmic}
\end{algorithm}

The genome is a real valued array X, where each element corresponds to one bin in the desired model (the number of bins n is defined by the problem). Each element $x_i \in X$ takes a value from $[0,1)$. In the initial population, these values are sampled from a uniform distribution and they are randomly generated. For more details of the genome representation, please refer to~\cite{ecta14}.\\


To clarify how the GAModel works, we use the same example as the one used in~\cite{ecta14}. The "Kanto" region, one of the four areas used in both studies, is divided into 2025 bins (a grid of 45x45 squares). Each bin has an area of approximately $25km^2$. The GAModel then calculates an expected number of earthquakes for every bin on a determinated time interval, so the GA searches for good values in 2025 bins.\\
\subsection{Fitness Function}\label{fitGA}

To compare the indididual data with the observated data, we use the log-likelihood calculation as fitness function. This equation allow us to compare events in the observated data with the values of occorrences obtained by a model. The models that have more similarity with to the observated data have bigger log-likelihood values. The fittest individual among all the others, is preserved inthe next generation, to make the solution of one generation as good as the its last generation.\\

The fitness function is a coded version of the equation ~\ref{log-fuction}. It uses the probabilities of the bins of each individual of model for the $\lambda$ values.\\

\subsection{Evolutionary Operators}\label{EvoGA}
The GAModel use a combination of operators made available by the Distributed Evolutionary Algorithms in Python (DEAP)~\cite{DeRainville:2012:DPF:2330784.2330799}. We used the One Point Crossover for the crossover operator, the Polynomial Bounded Mutation for the mutation operator and for selection, we used Tournament selection and Elitism. The parameters are described in the Table~\ref{GAParameters}.

\begin{table}[!ht]
  \caption{Parameters used in GAModel and Emp-GAModel}
  \label{GAParameters}
  \begin{center}
  \begin{tabular}{|l|r|}
    \hline
    Population Size & 500\\
    Generation Number & 100\\
    Elite Size & 1\\
    Tournament Size & 3\\
    Crossover Chance & 0.9\\
    Mutation Chance (individual) & 0.1\\
	Polynomial Bounded parameters & eta = 1, low = 0, up = 1\\
    \hline    
  \end{tabular}
  \end{center}
\end{table}

The parameters of the Polynomial Bounded mutation funcition are: add online ref???
\begin{enumerate}
\item eta = 1. Crowding degree of the mutation. A high eta will produce a mutant resembling its parent, while a small eta will produce a solution much more different;
\item o low = 0. The lower bound of the search space;
\item o up = 1. The upper bound of the search space.
\end{enumerate}

The chance of applying both mutation operator function and crossover operator function takes into account only their chance of occurrence. This means that it may be the case that one of them or both are not applied.\\

\section{ReducedGAModel}\label{ReducedGAModel}
The GAModel defines a expected number of earthquakes for every single bin in the target region. That could lead to exhaustive and, sometimes worthless, searches. That is caused by the number of bins in the forecast and also because in some bins there are no earthquake occurances in the observation data. That means that the GAModel has a lot of parameters and may of its bins have null values (values igual to 0). To avoid such unnecessary task we proposed the ReducedGAModel.\\

With this method, we aim to minimize the search space and the quantity of parameters the GA has to deal with. For that we changed the individual representation. The individuals in the ReducedGAModel only define expected number of earthquakes in bins that already had some occurance in the past, giving a direction to where the GA should search. That helps the ReducedGAModel in the search for better solutions and it makes the convergence faster once the space search is smaller.\\

The ReducedGAModel has a similar description of the GAModel. As said in the last paragraph, the difference is that, in the ReducedGAModel, each possible solution represents only a fraction of the forecast where we expect to find especific risk areas. To do so, this method will obtain the position of past occurances. Then it will calculate some expected number of earthquakes only for the bins related to those positions. These positions may vary during the evoluting of the method, including positions that never had earthquake events before. That is important to add some variation to the method.\\

The ReducedGAModel, as the GAModel~\ref{GAModel}, forecasts only earthquakes with magnitude greater than 3.0, for every scenario proposed. The space interval for the magnitude is 0.1, named as cells. That results in magnitude cells of [3.0, 3.1), [3.1, 3.2), until [9.9, 10).\\

\subsection{Genome Representation}\label{genomeReduced}
The genome representation in the ReducedGAModel is a simplified version of the genome of the GAModel. For the ReducedGAModel, the genome is a list of ordered pairs. The first element of the pair are the coordenates of a bin in the model. The second element of the pair is a number that indicates an earthquake occurrence estimative for this bin.\\

%TODO: explain this better
To calculate the size of the individual we use the real data from the pior 5 years and create a list of every bin that had events in it, even if only once.\\

In the ReducedGAModel, each individual is a list of a subregion of the forecast model. This list initially refers to bins where earthquake events happened in the past. During the develop of the ReducedGAModel, the list may refer to positions that never had occurrences before. Each element of the list, a gene, also contains one real value between [0,1). In the initial population, these values are sampled from a uniform distribution and they are randomly generated. When needed, every real value is converted to a integer forecast by the algorithm~\ref{inversePoisson}, as in the GAModel~\ref{GAModel}.\\

To generate the forecast model we need to do an intermediate step. We map every location from the list with a bin in the forecast model.\\

The genome size is usually smaller than the one used in the GAModel and the Emp-GAModel, once the amount of subregions where earthquakes with magnitude above 3.0 happened for any given area is smaller then the total number of genes of the individual.\\

To examplify, we use a similar example as the one in~\ref{GAModel}. Lets consider that there are 10 bins with occurances in "Kanto" in the last 5 years, it will make the GA start searching for good values for only those 10 bins, leaving the other 2015 bins empty, representing zero occurances. It is important to highlight that in the worst case, it will make the same amount of searches as the GAModel. The final forecast model will maintain the amount of bins with occurrance, but the number of events for every bin and their location may change.\\
\subsection{Fitness Function}
The fitness function is the same as in the GAModel,~\ref{fitGA}. Here is also important to generate the forecast model by applying the map function on the individual as in the last Section,~\ref{genomeReduced}.\\

\subsection{Evolutionary Operators}\label{gaOperators}
All operators in the ReducedGAModel are the same as the operators of the GAModel, except the the mutation fuction. We use a simple mutation operator which samples entirely two new values, both sampled from uniform distributions. The first, is a new real value from [0,1) and the seconde one, a new integer value from [0,$x$), where $x$ is the maximum position value a bin can have in the target region. For the parameters see Table~\ref{GAHParameters}.

\begin{table}[!ht]
  \caption{Parameters used in GAModel and Emp-GAModel}
  \label{GAHParameters}
  \begin{center}
  \begin{tabular}{|l|r|}
    \hline
    Population Size & 500\\
    Generation Number & 100\\
    Elite Size & 1\\
    Tournament Size & 3\\
    Crossover Chance & 0.9\\
    Mutation Chance (individual) & 0.1\\
    \hline    
  \end{tabular}
  \end{center}
\end{table}

As in the GAModel, see~\ref{EvoGA}, the chance of applying both mutation operator function and crossover operator are independent and they may or may not be used.\\

\section{Mainshock+Aftershock Models}\label{m+a+e}

%TODO: realocate to the right place
The Emp-ReducedGAModel and the Emp-GAModel differs only from the ReducedGAmodel and from the GAmodel, respectively, by the use of equations after the forecast is provided. This means that the theirs genome representation are the same as the GAModel and the ReducedGAModel,correspondingly.\\

Hence earthquakes cluster in space and inspired by the space-time
epidemic-type aftershock sequence (ETAS), the Emp-GAModel, represents
the ideia of associating the GA with empirical laws (see
Section~\ref{intro}). It is described as:

\begin{equation}\label{reducedgamodel}
	\Lambda(t,x,y,M|\Upsilon_t) = \mu(x,y)J(M)
\end{equation}


\begin{equation}\label{emp-model}
 \Lambda(t,x,y|\Upsilon_t) = \mu(x,y) + \displaystyle\sum_{t_i \in t} K(M_i)g(t-t_i)P(x,y)
\end{equation}
%TODO: explicar o Upsilon

The Emp-GAModel uses $\mu(x,y)$ as defined for the GAModel, so it calculates an expected number of earthquakes for every bin in the target region.\\

P(x,y) calculates the position of the aftershocks with base on the origin of the mainshock. It is a simple space distribuition function, that alocates the aftershocks in one of the following posotions: upper, lower, left or right. It runs for a number of steps, getting futter from the origin at each step or as when there are no more events to be alocated.\\

The Omori law, $g(t)$, which is considered one empirical formula of great success~\cite{zhuang2004analyzing}~\cite{utsu1995centenary}~\cite{omori1895after}, is a power law that relates the earthquake occurance and its magnitude
with the decay of aftershocks activity with time. For this approach we used the probabilty density function (pdf) form of the modifed Omori law~\cite{zhuang2004analyzing}:

\begin{equation}\label{omori}
	g(t)= \dfrac{(p-1)}{c(1+ \dfrac{t}{c})^(-p)}
\end{equation}

In the paper~\cite{utsu1995centenary}, Utsu says that most p and c
values, for various earthquake data sets fall in the range between 0.9
and 1.4, and between 0.003 and 0.3 days, respectively. These values
were based on the Davidon-Fletcher-Powell optimization procedure and
used in ETAS~\cite{utsu1995centenary}.\\

Based on paper~\cite{yamanaka1990scaling}, we set the values of $1.3$
for $p$ and $0.003$ for $c$ for our the experiments. Following the
statement make in this report, we set the time interval $t$ between a
mainshock and its aftershocks at one month. The statement says that if
the $t$ value is too short, the number of aftershocks is too small,
but if it is too big, we may also consider background activity.\\

For $K(M_i)$, the total amount of triggered events, we count
aftershocks within a given area, $A$, using the following formula,
where $M_c$ is the magnitude threshold:

\begin{equation}\label{triggered}
 K(M_i) = A\ exp([\alpha(M-M_c)])
\end{equation}

In the paper~\cite{ogata2006space}, it states that $\alpha$ should be
equal to the inverse of the magnitude of an event, or
$magnitide^{-1}$. To obtain $A$, the following equation
from~\cite{yamanaka1990scaling}, was used:

\begin{equation}
A = e^{(1.02M -4)}
\end{equation}


and lastly, the $J(M)$ is a simulation of the event magnitude by
Gutenberg-Richter's Law, using Add SAPP\\
% $1$ as the value of $\beta$ ~\cite{helmstetter2003predictability}:
%
%\begin{equation}\label{gut-ritcher}
%J(M) = \beta e^{-\beta(M-M_c)}, M \geq M_c
%\end{equation}

At last, the Emp-ReducedGAModel is a mix between the ideas in the
ReducedGAModel method and the Emp-GAModel, which means that its genome
representation is equal to the Emp-GAModel but its candidates have
same list of locations format, as in the ReducedGAModel.\\
\subsection{Emp-GAModel}
\subsubsection{Genome Representation}
\subsubsection{Fitness Function}
\subsubsection{Evolutionary Operators}
The Emp-GAModel use the same combination of operators that the GAModel. For more explanation, please see~\ref{gaOperators} and table~\ref{GAParameters}.\\

\subsection{Emp-ReducedGAModel}
\subsubsection{Genome Representation}
\subsubsection{Fitness Function}
\subsubsection{Evolutionary Operators}
For the ReducedGAModel and the Emp-ReducedGAModel, the only different
operator is the mutation fuction. We use a simple mutation operator
which samples entirely two new values, both sampled from uniform
distributions. The first, is a new real value from [0,1) and the
seconde one, a new integer value from [0,X), where X is the maximum
length of the genome. For the parameters see
Table~\ref{GAHParameters}.

\begin{table}[!ht]
  \caption{Parameters used in GAModel and Emp-GAModel}
  \label{GAHParameters-}
  \begin{center}
  \begin{tabular}{|l|r|}
    \hline
    Population Size & 500\\
    Generation Number & 100\\
    Elite Size & 1\\
    Tournament Size & 3\\
    Crossover Chance & 0.9\\
    Mutation Chance (individual) & 0.1\\
    \hline    
  \end{tabular}
  \end{center}
\end{table}
\section{Tests for evaluating Models}\label{Tests}

In the paper {\it Earthquake Likelihood Model
  Testing}~\cite{schorlemmer2007earthquake}, it is proposed some
statistical tests that are used in this study, developed by the The
Regional Earthquake Likelihood Models (RELM).They were used to compare
and evaluate the every forecast models. These test