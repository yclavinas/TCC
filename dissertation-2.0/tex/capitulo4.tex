%TODO: get some info from descricaoDetalhada
%\chapter{Models}~\label{chapter3}
As stated in the Section \ref{testing}, all forecast models proposed for this study are based in the Collaboratory for the Study of Earthquake Predictability (CSEP) framework.\\

We propose four forecast model methods. The main difference between them is that they have different genome representation. The genome for each forecast model focus on different aspects of the framework, therefore their represantion vary.\\

The first method is the GAModel~\cite{ecta14}, a statistical method of analysis of
earthquakes risk using the Genetic Algorithm technique (GA). It is a straight application of the CSEP framework. The next method is a specialization of GAModel. It focuses only on areas on which earthquakes happened already in a near past. This will lead to a faster convergence, once the amount of parameters is smaller and consequently, the search space gets smaller. We called it ReducedGAModel. These methods useonly computational algorithms and techniques.\\

Another method is the Emp-GAModel. This method incorpores some
geophysical knowledge. It is a hybridization of the models generated by the GAModel with some empirical laws that will be discussed further, in Section \ref{m+a+e}. We also applied these empirical laws in the ReducedGAModel, and name it Emp-ReducedGAModel.\\

For all methods, the population is evolved taking into account earthquake event data for a training period, which is anterior to the target test period. After completing the evaluation stop criteria, the best individual is chosen to be the representative forecast model for that method.\\

\section{1-year Forecast Models}\label{1year-model}
Based on the gridded rate forecast explained in the last Chapter~\ref{chapter2}, we developed earthquake forecasts methods that will estimate the risk of earthquakes occurrence to a target region, during a time interval. Some of the methods also may estime the magnitude of these shocks. For this study we considered the target time interval of one year~\cite{ecta14}.\\

There is no physical measurement to identify mainshocks and its aftershocks~\cite{schorlemmer2010first}, we divided the forecast models in two classes: the ones that only forecasts mainshocks, using only GA techniques, and those that forecast both mainshocks and aftershocks using both GA techniques and empirical laws, such as the modified Omori law. These laws are use to derive the aftershocks from a sintetic data of mainshocks.\\

%TODO: explain better what mainshock and aftershock are
Mainshocks are large and independent earthquakes. They are followed by a wave of others earthquakes, the aftershocks~\cite{schorlemmer2010first}.\\

\section{Main-shock Methods}\label{mainshocksMethods}
The mainshock methods are considered as methods to generate space-rate-time forecasts. They could be described as:

\begin{equation}\label{gamodel}
 \Lambda(t,x,y,M|\Upsilon_t) = \mu(x,y)
\end{equation}

where the number of earthquakes forecast in all bins can denoted as $\Lambda(t,x,y)$~\cite{zechar2010evaluating} given that $\Upsilon_t$ is the earthquake observation data up to time $t$.\\

\subsection{GAModel}\label{GAModel}
The GAModel is completely based on the framework suggested by the CSEP. In it, one forecast is defined as a region in a specfic time interval and is divided in bins. Each bin represents a geographical interval. The whole target area of study is covered by a group of these bins where each bin has an earthquake forecast value. This groups of bin represent the $\mu(x,y)$, the background intensity~\cite{zhuang2004analyzing}. In the GAModel, each possible solution is represented as an entire forecast model.\\

The GAModel forecasts only earthquakes with magnitude greater than 3.0, for every scenario proposed. The space interval for the magnitude is 0.1, named as cells. That results in magnitude cells of [3.0, 3.1), [3.1, 3.2), until [9.9, 10).\\

\subsubsection{Genome Representation}\label{genomeGA}
In the GAModel each individual represents an entire forecast model. Each gene of the individual is a real value, corresponding to one bin in the desired model. The values are sampled from the interval [0, 1). These real values are converted to a integer forecast, we use the same modification of the Poisson deviates extraction algorithm~\ref{inversePoisson} used in~\cite{ecta14}. In the algorithm $x$ is the real value that will be converted and $\mu$ is the mean of the earthquakes observations in the real data. \\

\begin{algorithm}\label{inversePoisson}
  \caption{Obtain a Poisson deviate from a $[0,1)$ value}
  \label{InversePoisson}
  \begin{algorithmic}
    \STATE Parameters $0 \leq x < 1, \mu \geq 0$
    \STATE $L \gets \exp{(-\mu)}, k \gets 0, prob \gets 1$
    \REPEAT 
    \STATE $\text{increment }k$
    \STATE $prob \gets prob*x$
    \UNTIL{$prob > L$}
    \RETURN $k$
  \end{algorithmic}
\end{algorithm}

The genome is a real valued array X, where each element corresponds to one bin in the desired model (the number of bins n is defined by the problem). Each element $x_i \in X$ takes a value from $[0,1)$. In the initial population, these values are sampled from a uniform distribution and they are randomly generated. For more details of the genome representation, please refer to~\cite{ecta14}.\\


To clarify how the GAModel works, we use the same example as the one used in~\cite{ecta14}. The "Kanto" region, one of the four areas used in both studies, is divided into 2025 bins (a grid of 45x45 squares). Each bin has an area of approximately $25km^2$. The GAModel then calculates an expected number of earthquakes for every bin on a determinated time interval, so the GA searches for good values in 2025 bins.\\
\subsubsection{Fitness Function}\label{fitGA}

To compare the indididual data with the observated data, we use the log-likelihood calculation as fitness function. This equation allow us to compare events in the observated data with the values of occorrences obtained by a model. The models that have more similarity with to the observated data have bigger log-likelihood values. The fittest individual among all the others, is preserved inthe next generation, to make the solution of one generation as good as the its last generation.\\

The fitness function is a coded version of the equation ~\ref{log-fuction}. It uses the probabilities of the bins of each individual of model for the $\lambda$ values.\\

\subsubsection{Evolutionary Operators}\label{gaOperators}
The GAModel use a combination of operators made available by the Distributed Evolutionary Algorithms in Python (DEAP)~\cite{DeRainville}. We used the One Point Crossover for the crossover operator, the Polynomial Bounded Mutation for the mutation operator and for selection, we used Tournament selection and Elitism. The parameters are described in the Table~\ref{GAParameters}.

\begin{table}[!ht]
  \caption{Parameters used in GAModel and Emp-GAModel}
  \label{GAParameters}
  \begin{center}
  \begin{tabular}{|l|r|}
    \hline
    Population Size & 500\\
    Generation Number & 100\\
    Elite Size & 1\\
    Tournament Size & 3\\
    Crossover Chance & 0.9\\
    Mutation Chance (individual) & 0.1\\
	Polynomial Bounded parameters & eta = 1, low = 0, up = 1\\
    \hline    
  \end{tabular}
  \end{center}
\end{table}

%TODO: put this under!
The parameters of the Polynomial Bounded mutation funcition are: add online ref???
\begin{enumerate}
\item eta = 1. Crowding degree of the mutation. A high eta will produce a mutant resembling its parent, while a small eta will produce a solution much more different;
\item o low = 0. The lower bound of the search space;
\item o up = 1. The upper bound of the search space.
\end{enumerate}

The chance of applying both mutation operator function and crossover operator function takes into account only their chance of occurrence. This means that it may be the case that one of them or both are not applied.\\

\subsection{ReducedGAModel}\label{ReducedGAModel}
The GAModel defines a expected number of earthquakes for every single bin in the target region. That could lead to exhaustive and, sometimes worthless, searches. That is caused by the number of bins in the forecast and also because in some bins there are no earthquake occurances in the observation data. That means that the GAModel has a lot of parameters and may of its bins have null values (values igual to 0). To avoid such unnecessary task we proposed the ReducedGAModel.\\

With this method, we aim to minimize the search space and the quantity of parameters the GA has to deal with. For that we changed the individual representation. The individuals in the ReducedGAModel only define expected number of earthquakes in bins that already had some occurance in the past, giving a direction to where the GA should search. That helps the ReducedGAModel in the search for better solutions and it makes the convergence faster once the space search is smaller.\\

The ReducedGAModel has a similar description of the GAModel. As said in the last paragraph, the difference is that, in the ReducedGAModel, each possible solution represents only a fraction of the forecast where we expect to find especific risk areas. To do so, this method will obtain the position of past occurances. Then it will calculate some expected number of earthquakes only for the bins related to those positions. These positions may vary during the evoluting of the method, including positions that never had earthquake events before. That is important to add some variation to the method.\\

The ReducedGAModel, as the GAModel~\ref{GAModel}, forecasts only earthquakes with magnitude greater than 3.0, for every scenario proposed. The space interval for the magnitude is 0.1, named as cells. That results in magnitude cells of [3.0, 3.1), [3.1, 3.2), until [9.9, 10).\\

\subsubsection{Genome Representation}\label{genomeReduced}
The genome representation in the ReducedGAModel is a simplified version of the genome of the GAModel. For the ReducedGAModel, the genome is a list of ordered pairs. The first element of the pair are the coordenates of a bin in the model. The second element of the pair is a number that indicates an earthquake occurrence estimative for this bin.\\

%TODO: explain this better
To calculate the size of the individual we use the real data from the pior 5 years and create a list of every bin that had events in it, even if only once.\\

In the ReducedGAModel, each individual is a list of a subregion of the forecast model. This list initially refers to bins where earthquake events happened in the past. During the develop of the ReducedGAModel, the list may refer to positions that never had occurrences before. Each element of the list, a gene, also contains one real value between [0,1). In the initial population, these values are sampled from a uniform distribution and they are randomly generated. When needed, every real value is converted to a integer forecast by the algorithm~\ref{inversePoisson}, as in the GAModel~\ref{GAModel}.\\

To generate the forecast model we need to do an intermediate step. We map every location from the list with a bin in the forecast model.\\

The genome size is usually smaller than the one used in the GAModel and the Emp-GAModel, once the amount of subregions where earthquakes with magnitude above 3.0 happened for any given area is smaller then the total number of genes of the individual.\\

To examplify, we use a similar example as the one in~\ref{GAModel}. Lets consider that there are 10 bins with occurances in "Kanto" in the last 5 years, it will make the GA start searching for good values for only those 10 bins, leaving the other 2015 bins empty, representing zero occurances. It is important to highlight that in the worst case, it will make the same amount of searches as the GAModel. The final forecast model will maintain the amount of bins with occurrance, but the number of events for every bin and their location may change.\\

\subsubsection{Fitness Function}
The fitness function is the same as in the GAModel,~\ref{fitGA}. Here is also important to generate the forecast model by applying the map function on the individual as in the last Section,~\ref{genomeReduced}.\\

\subsubsection{Evolutionary Operators}\label{ReducedOperators}
All operators in the ReducedGAModel are the same as the operators of the GAModel, except the the mutation fuction. We use a simple mutation operator which samples entirely two new values, both sampled from uniform distributions. The first, is a new real value from [0,1) and the seconde one, a new integer value from [0,$x$), where $x$ is the maximum position value a bin can have in the target region. For the parameters see Table~\ref{GAHParameters}.

\begin{table}[!ht]
  \caption{Parameters used in ReducedGAModel}
  \label{GAHParameters}
  \begin{center}
  \begin{tabular}{|l|r|}
    \hline
    Population Size & 500\\
    Generation Number & 100\\
    Elite Size & 1\\
    Tournament Size & 3\\
    Crossover Chance & 0.9\\
    Mutation Chance (individual) & 0.1\\
    \hline    
  \end{tabular}
  \end{center}
\end{table}

As in the GAModel, see~\ref{gaOperators}, the chance of applying both mutation operator function and crossover operator are independent and they may or may not be used.\\

\section{Main-shock with After-shock Methods}\label{m+a+e}
%TODO: add the var right values and "faixa"
The main-shock and after-shock methods are a two-step methods. The first step is as defined for the main-shocks methods, therefore, we first use GA techniques to obtain a synthetic main-shock data. The second step is to use seismological empirical equations to obtain the aftershocks from the main-shocks\\


Hence earthquakes cluster in space and inspired by the space-time epidemic-type aftershock sequence (ETAS), we proposed two methods, called Emp-GAModel and Emp-ReducedGAModel. They represent the idea of associating the GA with seismological empirical equations. They are described as:

\begin{equation}\label{reducedgamodel}
	\Lambda(t,x,y,M|\Upsilon_t) = \mu(x,y)J(M)
\end{equation}

That can be expanded to:

\begin{equation}\label{emp-model}
 \Lambda(t,x,y|\Upsilon_t) = \mu(x,y) + \displaystyle\sum_{t_i \in t} K(M_i)g(t-t_i)P(x,y)
\end{equation}
%TODO: explicar o Upsilon

The main-shock and after-shock methods use $\mu(x,y)$ as defined for main-shock methods~\ref{mainshocksMethods}. It is calculated as an expected number of earthquakes for every bin in the target region, given that $\Upsilon_t$ is the earthquake observation data up to time $t$.\\

\subsubsection{Empirical Equations}

The Omori law, $g(t)$, which is considered one empirical formula of great success~\cite{zhuang2004analyzing}\cite{utsu1995centenary}\cite{omori1895after}, is a power law that relates the earthquake occurrence and its magnitude with the decay of aftershocks activity with time. For this approach we used the probability density function (PDF) form of the modified Omori law~\cite{zhuang2004analyzing}:

\begin{equation}\label{omori}
	g(t)= \dfrac{(p-1)}{c(1+ \dfrac{t}{c})^(-p)}
\end{equation}

The variable $p$ is a index of this equation and the variable $c$ is a constant, given in days. In the paper~\cite{utsu1995centenary}, Utsu summarise most of the studies in Japan and described the range for these variables. For $p$ the range is between 0.9 and 1.4 and for $c$, 0.003 and 0.3 days. These values were based on the Davidon-Fletcher-Powell optimisation procedure and used in ETAS~\cite{utsu1995centenary}. Also there is the variable $t$ that is the time limit to when a main-shock may influence the cause a aftershock.\\

TODO: should i move this to exp??
Based on paper~\cite{yamanaka1990scaling}, we set the values of $1.3$ for $p$ and $0.003$ for $c$ for our experiments. We set the time interval $t$ between a main-shock and its aftershocks at one month. In the paper, it says that if the $t$ value is too short, the number of aftershocks is too small, but if it is too big, we may also consider background activity and suggest the use of a 30 days period.\\

For $K(M_i)$, the total amount of triggered events, we count aftershocks within a given area, $A$, using the following formula, where $M_c$ is the magnitude threshold:

\begin{equation}\label{triggered}
 K(M_i) = A\ exp([\alpha(M_i-M_c)])
\end{equation}

In the paper~\cite{ogata2006space}, it states that $\alpha$ should be equal to the inverse of the magnitude of an event, or $magnitude^{-1}$. To obtain $A$, the following equation from~\cite{yamanaka1990scaling}, was used:

\begin{equation}
A = e^{(1.02M -4)}
\end{equation}

With the $K(Mi)$ and $g(t)$, the PDF Omori, equations it is possible to calculate the total number of earthquakes. For that we must sum the product of the equations, varying $t$:

\begin{equation}
\displaystyle\sum_{t_i \in t} K(M_i)g(t-t_i)
\end{equation}

This result will lead to a number of aftershocks related to a single main-shock Then, we can use the $P(x,y)$ equation to distribute the aftershock to the bins near the main-shock’s position.  $P(x,y)$ calculates the position of the aftershocks with base on the origin of the main-shock. It is a simple space distribuition function, that alocates the aftershocks in one of the following positions: upper, lower, left or right. It runs for a number of steps, getting futter from the origin at each step or as when there are no more events to be alocated.$P(x,y)$ can be splited into 4 equations, one for each position:\\

\begin{subequations}
\begin{gather*}
        model[x+y] = (aftershocks-[model[x]-2*x])/4;\\
        model[x-y] = (aftershocks-[model[x]-2*x])/4;\\
        model[x-y*row] = (aftershocks-[model[x]-2*x])/4;\\
        model[x+y*row] = (aftershocks-[model[x]-2*x])/4
\end{gather*}
\end{subequations}


and lastly, the $J(M)$ is a simulation of the event magnitude by
Gutenberg-Richter's Law, using Add SAPP\\
%α1: mede a eficiência de um abalo sísmico com uma certa
%magnitude em causar aftershocks. [1] Valor utilizado: 2.34 [3];
%Faixa de valores: 0.2 <= α1 <= 3.0 [1]
%o K:quantidadedeterremotos,dependentedosdados[4]
%o μ -> é uma taxa de mainshocks constante no tempo. Valor utilizado: 0.01548, dependente dos dados – se depende dos dados deveria usar outro valor, ainda não achei informação
%sobre o range de μ. [1]
% $1$ as the value of $\beta$ ~\cite{helmstetter2003predictability}:
%
%\begin{equation}\label{gut-ritcher}
%J(M) = \beta e^{-\beta(M-M_c)}, M \geq M_c
%\end{equation}


\subsection{Emp-GAModel}\label{emp-gamodel}
The Emp-GAModel is a specialization of the GAmodel. This is achieved by the use of empirical equations after the forecast is provided. This means that the its genome representation are the same as the GAModel.\\
\subsubsection{Genome Representation}
The genome representation is the same as in the GAModel,~\ref{genomeGA}.\\

\subsubsection{Fitness Function}
The fitness function is the same as in the GAModel,~\ref{fitGA}, and the ReducedGAModel.\\
\subsubsection{Evolutionary Operators}
The Emp-GAModel use the same combination of operators that the GAModel. For more explanation, please see~\ref{gaOperators} and Table~\ref{GAParameters}.\\

\subsection{Emp-ReducedGAModel}\label{emp-reducedgamodel}
The Emp-ReducedGAModel is a specialization of the ReducedGAmodel. This is achieved by the use of empirical equations after the forecast is provided. This means that the its genome representation are the same as ReducedGAModel.\\

\subsubsection{Genome Representation}
The genome representation is the same as in the ReducedGAmodel,~\ref{genomeReduced}. \\

\subsubsection{Fitness Function}
The fitness function is the same afor all methods,~\ref{fitGA}. Here is also important to generate the forecast model by applying the map function on the individual as in the last Section,~\ref{genomeReduced}.\\

\subsubsection{Evolutionary Operators}
The Emp-ReducedGAModel use the same combination of operators that the ReducedGAModel. For more explanation, please see~\ref{gaOperators} and Table~\ref{ReducedOperators}.\\

%\section{Tests for evaluating Models}\label{Tests}
%
%In the paper {\it Earthquake Likelihood Model Testing}~\cite{schorlemmer2007earthquake}, it is proposed some statistical tests that are used in this study, developed by the The Regional Earthquake Likelihood Models (RELM). They were used to compare and evaluate the forecast models. These tests are based on the log-likelihood score that compares the data of a model with the observed data.\\
%
%To evalute the data-consistency of the forecast models we used the N-Test, the Number Test, and the L-Test, or Likelihood Test. These tests fall are significance tests. Therefore, assuming a given forecast model as the null hypothesys, the distribuition of an observable test is simulated. If the observed test statistic falls into the upper or lower tail of this distribuition, the forecast is
%rejected~\cite{schorlemmer2010first}.\\
%
%To be able to compare the model that passed the N-Test and the L-test, the R-Test, the hypotheses Comparison Test, is used. It calculates the relative performance of two models, by comparing the Log-likelihood values obtained from them.\\
%
%\subsection{Likelihood Test or L-Test}
% 
%The L(ikelihood) Test considers that the likelihood value of the model is consistent with the value obtain with the simulations. The value is calculated by the formula, where $\widehat{L}_k$ is the value of the Log-likelihood of the model {\it j}, in the {\it bin} {\it i} and $\widetilde{L}$ is the value of the Log-likelihood of the simulation {\it j} in the {\it bin} {\it q}:
%
%
%\begin{equation}
%\gamma^{j}_{q} = \frac{\left| \left\{ \widehat{L}^j_k | \widehat{L}^j_k \leq \widetilde{L}^j_q, \widehat{L}^j_k \in \widehat{L}^j, \widetilde{L}^j_q \in \widetilde{L}^j  \right\} \right|}  {|\widehat{L}^j|}
%\end{equation}
%
%The analisys of the results can be splited into 3 categories, as follows:
%
%\begin{enumerate}
%\item Case 1: $\gamma^{j}$ is a low value, or in other words, the
%  Log-likelihood of the model is lower then most of the Log-likelihood
%  of the simulations. In this case, the model is rejected.
%\item Case 2: $\gamma^{j}$ falls near the half of the values obtained
%  from the simluations and is consistent with the data.
%\item Case 3: $\gamma^{j}$ is high. This means that the Log-likelihood
%  of the data da is higher that the Log-likelihood of the model and no
%  conclusion can be made what so ever.
%\end{enumerate}
%
%
%It is important to highlight that no model should be reject in case 3, if based only on the L-Test. In this case the consistency can or cannot be real, therefore these model should be tested by the N-Test so that further conclusions can be done.\\
%
%\subsection{Number test or N-Test}
%The N(umber)-Test also analises the consistency of the model, but it compares the number os observations with the number of events of the simulations. This test is necessary to supply the underpredicting problem, indicating whether a forecast has predicted too few earthquakes, which may pass unnoticed by the L-Test.\\
%
%This mesure is estimated by the fraction of the total number of observations by the total number of observations of the model.\\
%
%As the L-test, if the number of events falls near the half of the values of the distruition, then the model is consistent with the observation, nor estimating too much events nor too few of them.\\
%
%\subsection{Hypotheses Comparison Test or R-Test}
%
%The Hypotheses Comparison, or the R(atio)-Test, compares two forecast models against themselves. The log-likelihood is calculted for both models and then the difference between them is calculated, named the observed likelihood ratio. This value indicates which one of the model better fits the observations.\\
%
%The likelihood ratio is calculated for each simulated catalog. If the fraction of simulated likelihood ratios less than the observed likelihood ratio is very small, the model is reject.  To make this test impartial, not given an advantage to any model, this procedure is applied symmetrically~\cite{schorlemmer2010first}.\\
%
%
%\subsection{Evaluation}\label{eval}
%The evaluation process is made as follow: First, the data-consitency is tested by the L-Test and the R-test. If the model passes these tests, meaning that it was not rejected by them, they ares compared with other forecast models, which were also not reject, with the R-Test. The model that best fits the R-Test is then chose as the best model~\cite{schorlemmer2007earthquake}.\\
